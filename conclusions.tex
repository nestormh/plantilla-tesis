%%
%%  chapter00.tex - Obstacle Detection and Planning for Autonomous Vehicles based on Computer Vision Techniques
%%
%%  Copyright 2014 Néstor Morales <nestor@isaatc.ull.es>
%%
%%  This work is licensed under a Creative Commons Attribution 4.0 International License.
%%

\addchap{Conclusions}

In this thesis, four different object detection tracking approaches, two methods for global and local path planning and a evaluation of two state-of-the-art algorithms with different configurations have been presented. Based on this, the goal of this thesis, the study of computer vision methods for obstacle detection and their avoidance for the Verdino prototype, is achieved.

The first of these approaches was based on the generation of a database in which each image had geographical information associated. In real time, the vehicle captured images from the onboard images and those were compared with the nearest image in the database by using classical image registration techniques. The changes detected were the obstacles in the way of the vehicle. 

With this approach, we evaluated the influence of the distance and angle difference between the compared images to the quality of the results. Conclusions were that the method works properly if distance is below 1\,m and the angle difference is below 10\textdegree. We also evaluated the influence of the illumination difference between images, concluding that the best results were obtained when this difference was below 20\%.

However, this approach has some limitations that can not be overcome using image registration techniques. First, we need a highly populated database if we want to be sure that we fulfill the distance and brightness difference limitations established. Also, as we are working with just an image of the camera, we can not locate the obstacles detected in real world coordinates. Finally, we know where the obstacles are, but we do not know were are they going to, so we need a tracking mechanism.

With these limitations in mind, we decided to isolate the last problem and develop a method for the tracking of generic obstacles without the need of a model in scenes captured by static cameras. The peculiarity of this method is that we do not track the obstacles as a whole object but we detect the trajectory followed by each part of them independently, detecting the flow of their contour.

The method consisted on the segmentation of the foreground of the scene using some state-of-the-art methods, extracting the contour of the obstacles. This contour was tracked between frames using a non rigid point set registration method, getting a match between points of different frames. These matches, joined along the frames, formed the trajectories of the points.

With this method, we demonstrated that is was possible to do such a tracking by using just geometrical information. Also, we evaluated the behavior of four different foreground segmentation methods (\cite{lopez2011stochastic, lopez2011foreground, guo2011hierarchical, reddy2012improved}), demonstrating that that from \cite{reddy2012improved} was the one that fulfilled the most our needs. Same was done for the six non rigid point set registration methods, of which the Coherent Point Drift was the one that gave the best results. Also, we compared our method with a simple optical flow tracker and a Kinect based method, showing that our method gave better results in certain circumstances.

However, the method is still not enough for our goal. It depends on static cameras, while we want to use the tracker with the images captured by the onboard cameras. Because of that, we started exploring some 3D reconstruction algorithms, and we found different approaches. Most of them were based on dense reconstruction, while some of them did a simplification of the reconstructed world by assuming certain conditions.

Inside the dense reconstruction methods, there were many different algorithms, making the choice difficult. One of the contributions of this thesis is the development of a automatized framework for the evaluation of dense reconstruction algorithms. This framework allows testing the algorithms using long sequences, at different weather and illumination conditions. This solved the problem existing for other previous evaluations in which the testing images were taken in laboratories, under controlled conditions; or in which sequences were too short with a ground truth edited by hand.

In these evaluation tests, we found some interesting results. We concluded that the use of filtering strategies reduces the number of wrong pixels and enhances the accuracy of the results. About the strategies used for the evaluation of the algorithms, we demonstrated that it is possible to do such statistics without the need of a \ac{LIDAR}-based ground truth (which despite of the great reliability of the statistics obtained with it, it is quite expensive in terms of the required equipment and the time needed for the post-processing of the captured data). The use of a prior on the vehicle movement was successfully exploited to identify a portion of the wrongly reconstructed points, making it suitable for the evaluation of big data-sets, thus covering a broad range of environmental conditions. In the other hand, the use of a third camera for evaluation looks feasible, but in practice the obtained results were not very discriminative.

We also explored other alternatives to dense reconstruction. Starting from the works in \cite{benenson2011stixels} and \cite{gunyel2012stixels}, we successfully developed a method for obstacle detection and tracking based on the stixels world described in \cite{badino2009stixel}. With this work, we shown that the use of a two-level tracking allows outperforming the existing methods about tracking in this field. Also the use of the Hellinger distance improved the tracking results. Apart from that, we also shown that, if speed is preferred over accuracy, object based tracking is possible, in which objects are obtained through a simple clustering method and then are tracked by using the illumination information between the obstacles.

Going back to the dense reconstruction methods, we also developed a tracking method able to receive a point cloud as input and detect the objects and their movement direction and speed, based just on their position in real world coordinates and a particle filter. Although we centered this work on dense stereo reconstruction based point clouds, it is also able to work with point clouds provided by other sensors, like for example \acp{LIDAR}, as we are not using color information. This is done thanks also to a modular implementation of the method. The use of a particle filter based approach allows avoiding complex probabilities-related calculations, and the use of a voxel grid allows working in three dimensions without increasing the complexity, as well as a more specific knowledge of the obstacle, which is not limited just to the more external boundaries of the obstacle through the use of cuboids.

Based on the detected obstacles, we developed a path planner scheme that allows the vehicle to reach a goal in the map while avoiding those objects. We divided this scheme into global and local planner. With the global planner, we shown a different strategy for the generation of trajectories based on \ac{MSVM}, in which each obstacle was a class, and the decision borders the possible paths, which were joined together with the use of a \acl{NNG} and a \acl{RNG}. This graph was updated with the new obstacles, avoiding to compute the whole graph again. The advantages of using this method as a base is that we can generate continuous non-linear border lines that allow the creation of smooth, short and safe paths. The use of the \ac{GPU} reduces the required computational time. 

About the local planner, we developed a method that, based on the Frenét space is able to generate smooth paths that allow, at the same time, following the trajectory and avoiding the obstacles in the way. Generation of the tentative paths is simplified as speed is out of the model of the tracks generation, so it is reduced to the computation of a set of parameters that define a third order polynomial. We also use different lateral offsets with respect to the global plan, so the avoidance of the obstacles is considered. Then, the use of a cost function allows selecting the best path.

With all these methods working, we put the best of them all together, showing that they were completely suitable for the application for which they were thought. We used our planner together with both the stixels world and the particle filter approaches. We observed that both were good enough to be used for obstacle detection and avoidance tasks, except from the limitations we already knew for them (i.e., the need of a planar ground for the stixels, or the assumption of a maximal speed between frames for the \ac{PF} based approach).

\addsec{Future Work}

Usar otras características que permitan aumentar el ángulo -> Hablar de SURF y la GPU
Usar el método para el análisis de cambios en vídeos

Usar la salida para hacer algo
Pasar al 3D mediante la segmentación bg/fg de imágenes dinámicas
Permitir una mayor cantidad de dimensiones mediante una implementación eficiente del CPD
Usar info del color
Usar la técnica empleada en la fase de evaluación para 

The use of a third camera for evaluation (section \ref{ch:chapter03_03}) is conceptually appealing, but in practice has shown to produce poor results. Further testing will be needed to assess its real effectiveness in real-world scenarios. In the future, we expect to perform more experiments including more sequences with different atmospheric conditions like other hours in a day, as well as the use of different metrics to measure the similarity between the control camera and virtual images.

In the future, we want to try to improve the way in which stixels are computed. We think that using the polar rectification for combining tracking and reconstruction could give good results. Also, the use of a measure of the goodness of the tracks at stixel level should help to improve the results obtained for the clustering process.

In the future, we plan to do further research in order to improve the results given by the method. Some ideas are related to the use of color ( despite it would affect to the modularity of our system) as using more information should improve the output. We also think that using a polar voxel grid instead of a cartesian one would improve some results. Also, it would be a good idea to use a Kalman filter in order to track the detected obstacles, so we would know not just their position and current speed, but also their movement along the frames. Finally, we could take advantage of the big amount of operations that are done individually for each voxel and do a parallelized implementation that allows improving the algorithm frequency a little bit more or using a bigger number of particles.

Para el global planner, explorar estrategias de clustering. Combinar el uso de MSVM con Voronoi

As future work, we can study the inclusion of new costs or long-term control strategies, as those used in \cite{werling2010optimal}. Also, the computation of the steering angle based on the winner path is quite rudimentary. We propose as future work the use of a PID controller or even a predictive one, as that explained in \todocite{XXX-espelosin}.