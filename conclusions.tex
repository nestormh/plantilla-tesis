%%
%%  chapter00.tex - Obstacle Detection and Planning for Autonomous Vehicles based on Computer Vision Techniques
%%
%%  Copyright 2014 Néstor Morales <nestor@isaatc.ull.es>
%%
%%  This work is licensed under a Creative Commons Attribution 4.0 International License.
%%

\addchap{Conclusions}

In this thesis, four different object detection tracking approaches, two methods for global and local path planning and a evaluation of two state-of-the-art algorithms with different configurations have been presented. Based on this, the goal of this thesis, the study of computer vision methods for obstacle detection and their avoidance for the Verdino prototype, is achieved.

The first of these approaches was based on the generation of a database in which each image had geographical information associated. In real time, the vehicle captured images from the onboard images and those were compared with the nearest image in the database by using classical image registration techniques. The changes detected were the obstacles in the way of the vehicle. 

With this approach, we evaluated the influence of the distance and angle difference between the compared images to the quality of the results. Conclusions were that the method works properly if distance is below 1\,m and the angle difference is below 10\textdegree. We also evaluated the influence of the illumination difference between images, concluding that the best results were obtained when this difference was below 20\%.

However, this approach has some limitations that can not be overcome using image registration techniques. First, we need a highly populated database if we want to be sure that we fulfill the distance and brightness difference limitations established. Also, as we are working with just an image of the camera, we can not locate the obstacles detected in real world coordinates. Finally, we know where the obstacles are, but we do not know were are they going to, so we need a tracking mechanism.

With these limitations in mind, we decided to isolate the last problem and develop a method for the tracking of generic obstacles without the need of a model in scenes captured by static cameras. The peculiarity of this method is that we do not track the obstacles as a whole object but we detect the trajectory followed by each part of them independently, detecting the flow of their contour.

The method consisted on the segmentation of the foreground of the scene using some state-of-the-art methods, extracting the contour of the obstacles. This contour was tracked between frames using a non rigid point set registration method, getting a match between points of different frames. These matches, joined along the frames, formed the trajectories of the points.

With this method, we demonstrated that is was possible to do such a tracking by using just geometrical information. Also, we evaluated the behavior of four different foreground segmentation methods (\cite{lopez2011stochastic, lopez2011foreground, guo2011hierarchical, reddy2012improved}), demonstrating that that from \cite{reddy2012improved} was the one that fulfilled the most our needs. Same was done for the six non rigid point set registration methods, of which the Coherent Point Drift was the one that gave the best results. Also, we compared our method with a simple optical flow tracker and a Kinect based method, showing that our method gave better results in certain circumstances.

However, the method is still not enough for our goal. It depends on static cameras, while we want to use the tracker with the images captured by the onboard cameras. Because of that, we started exploring some 3D reconstruction algorithms, and we found different approaches. Most of them were based on dense reconstruction, while some of them did a simplification of the reconstructed world by assuming certain conditions.

Inside the dense reconstruction methods, there were many different algorithms, making the choice difficult. One of the contributions of this thesis is the development of a automatized framework for the evaluation of dense reconstruction algorithms. This framework allows testing the algorithms using long sequences, at different weather and illumination conditions. This solved the problem existing for other previous evaluations in which the testing images were taken in laboratories, under controlled conditions; or in which sequences were too short with a ground truth edited by hand.

In these evaluation tests, we found some interesting results. We concluded that the use of filtering strategies reduces the number of wrong pixels and enhances the accuracy of the results. About the strategies used for the evaluation of the algorithms, we demonstrated that it is possible to do such statistics without the need of a \ac{LIDAR}-based ground truth (which despite of the great reliability of the statistics obtained with it, it is quite expensive in terms of the required equipment and the time needed for the post-processing of the captured data). The use of a prior on the vehicle movement was successfully exploited to identify a portion of the wrongly reconstructed points, making it suitable for the evaluation of big data-sets, thus covering a broad range of environmental conditions. In the other hand, the use of a third camera for evaluation looks feasible, but in practice the obtained results were not very discriminative.

We also explored other alternatives to dense reconstruction. Starting from the works in \cite{benenson2011stixels} and \cite{gunyel2012stixels}, we successfully developed a method for obstacle detection and tracking based on the stixels world described in \cite{badino2009stixel}. With this work, we shown that the use of a two-level tracking allows outperforming the existing methods about tracking in this field. Also the use of the Hellinger distance improved the tracking results. Apart from that, we also shown that, if speed is preferred over accuracy, object based tracking is possible, in which objects are obtained through a simple clustering method and then are tracked by using the illumination information between the obstacles.

Going back to the dense reconstruction methods, we also developed a tracking method able to receive a point cloud as input and detect the objects and their movement direction and speed, based just on their position in real world coordinates and a particle filter. Although we centered this work on dense stereo reconstruction based point clouds, it is also able to work with point clouds provided by other sensors, like for example \acp{LIDAR}, as we are not using color information. This is done thanks also to a modular implementation of the method. The use of a particle filter based approach allows avoiding complex probabilities-related calculations, and the use of a voxel grid allows working in three dimensions without increasing the complexity, as well as a more specific knowledge of the obstacle, which is not limited just to the more external boundaries of the obstacle through the use of cuboids.

Based on the detected obstacles, we developed a path planner scheme that allows the vehicle to reach a goal in the map while avoiding those objects. We divided this scheme into global and local planner. With the global planner, we shown a different strategy for the generation of trajectories based on \ac{MSVM}, in which each obstacle was a class, and the decision borders the possible paths, which were joined together with the use of a \acl{NNG} and a \acl{RNG}. This graph was updated with the new obstacles, avoiding to compute the whole graph again. The advantages of using this method as a base is that we can generate continuous non-linear border lines that allow the creation of smooth, short and safe paths. The use of the \ac{GPU} reduces the required computational time. 

About the local planner, we developed a method that, based on the Frenét space is able to generate smooth paths that allow, at the same time, following the trajectory and avoiding the obstacles in the way. Generation of the tentative paths is simplified as speed is out of the model of the tracks generation, so it is reduced to the computation of a set of parameters that define a third order polynomial. We also use different lateral offsets with respect to the global plan, so the avoidance of the obstacles is considered. Then, the use of a cost function allows selecting the best path.

With all these methods working, we put the best of them all together, showing that they were completely suitable for the application for which they were thought. We used our planner together with both the stixels world and the particle filter approaches. We observed that both were good enough to be used for obstacle detection and avoidance tasks, except from the limitations we already knew for them (i.e., the need of a planar ground for the stixels, or the assumption of a maximal speed between frames for the \ac{PF} based approach).

\addsec{Future Work}

However, there is still much work to do and many things that could be improved. 

\begin{itemize}
 \item We saw that one of the limitations of the method is the maximal distance and angle between the images. Because of that, we think that using other method for the matching of features between images is possible. In fact, we have done some tests in which we used the \ac{GPU} for the computation and matching of \ac{SURF} features (\cite{bay2008speeded}), in which the times obtained were suitable for such approach.
 \item This method could be used also for other tasks as the improvement of some of the existing change detection methods for aligned video sequences, like those presented by \cite{diego2011video, evangelidis2011slice, evangelidis2011efficient}.
 \item The output obtained for the non rigid contour tracking method described is still not being used at all. We think that this output could be used for many applications, not just related to \ac{ADAS}, but also to motion analysis in videos or \ac{HMI} systems.
 \item We would like to go beyond the use of static bidimensional image sequences, and extend the method to 3D. A way to do that would the segmentation of a disparity map, in which the contours used would be the borders of the segmented regions. Then, these could be easily transformed to real world coordinates.
 \item Another way to do that would be through the addition of new dimensions to the points used in the non-rigid point set registration step. Despite the Coherent Point Drift algorithm allows doing that, it would require the optimization of the current implementation we are using of this method. This will also allow including color information easily. We started a \ac{CUDA} based implementation of this method, with promising results.
 \item Despite the method used in the results section for the evaluation of this tracking method is reset each frame, we would like to extend it in order to use it for the analysis of the movement of an object. This would require to generate a model of the tracked object, but the analysis of its movement could be done through this method.
 \item About the evaluation of the dense reconstruction methods, the use of a third camera was promising, but results were not as good as expected. In the future, we expect to use different metrics to measure the similarity between the control camera and virtual images. Also more experiments could be performed, including sequences with different atmospheric conditions like other hours in a day.
 \item We also want to try new methods for stixels computation. A possibility would be using the polar rectification for the combination of tracking and reconstruction in a single process. 
 \item We could use the tracking output as a clue for the clustering process, in which we just use the stixels for which a correspondence is found for the clustering process.
 \item The particle filter based approach is using just position information for the tracking of the obstacles. We think that results would be improved if color information is used. This will avoid the use of sensors different from stereo cameras, but we could think on an schema in which several sensors are joined, being a stereo pair one of them.
 \item We also would like to track the trajectories of the obstacles along the sequences, which is not being done right now.
 \item We also want to do a parallel implementation of the method, which should be easy to perform and will give better results in term of time used.
 \item Regarding to the path planning methods, there also some work that could be done. For example, new clustering strategies could be applied for the global planner.
 \item Also, the use of \ac{MSVM} could be combined with other classical approaches.
 \item New cost of long-term control strategies could be applied for the generation and selection of the candidate paths in the local planner.
 \item The final selection of the applied steering angle and speed could be improved. Some approaches we have considered are the use of a \ac{PID} controller or even more complex control strategies, as a predictive controller.
\end{itemize}

Finally, with all these systems working, it would be interesting to do a more tight combination of them in which, based on the tracked obstacles, Verdino will be able to predict the future motion of the obstacles, giving it a behavior quite close to that followed by humans.

And then, maybe humans will not have to drive.