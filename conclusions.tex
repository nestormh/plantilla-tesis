%%
%%  chapter00.tex - Obstacle Detection and Planning for Autonomous Vehicles based on Computer Vision Techniques
%%
%%  Copyright 2014 Néstor Morales <nestor@isaatc.ull.es>
%%
%%  This work is licensed under a Creative Commons Attribution 4.0 International License.
%%

\addchap{Conclusions}

The main goal of this thesis is the study of Computer Vision based methods for obstacle detection and avoidance applied to the Verdino prototype. In order to achieve this, four different object detection and tracking approaches, one method for global and other of local path planning and a methodology for the automatic evaluation of stereo vision based reconstruction algorithms were presented.

The very first approach was based on the generation of a database in which each image was associated to geographical information. In real time, the vehicle captures images from the onboard cameras, which are compared to the nearest image in the database through classical image registration techniques. The detected changes were the obstacles in the way of the vehicle. 

Through this approach, we evaluated the influence of the distance and angle difference between the compared images to the quality of the results. Conclusions were that the method works properly if distance is below 1\,m and the angle difference is below 10\textdegree. We also evaluated the influence of illumination difference between images, concluding that best results were obtained when this difference was below 20\%.

However, this approach had some limitations that can not be overcome using image registration techniques: First, if we want to be sure that we fulfill the distance and brightness difference limitations established, we need a highly populated database . Also, as we are working with monocular images, we can not locate the obstacles detected in real world coordinates. Finally, we know where the obstacles are but we can not predict their movement, so we need a tracking mechanism.

With these limitations in mind, we decided to isolate just the last problem and develop a method for tracking generic obstacles without the need of a model in scenes captured by static cameras. The peculiarity of this method is that we do not track the obstacles as a whole object, but we detect the trajectory followed by each part of them independently, detecting the flow of their contour.

The method consisted on the segmentation of the foreground of the scene using some state-of-the-art methods, extracting the contour of the obstacles. This contour was tracked between frames using a non rigid point set registration method, getting matches between points in the borders of obstacle silhouettes obtained at different frames. These matches, joined along the frames, formed the trajectories of the points.

With this method, we demonstrated that it was possible to do such a tracking by using just geometrical information. Also, we evaluated the behavior of four different foreground segmentation methods \citep{lopez2011stochastic, lopez2011foreground, guo2011hierarchical, reddy2012improved}, demonstrating that the method presented by \cite{reddy2012improved} was the one that fulfilled the most of our needs. Same was done for six different non rigid point set registration methods, from which the Coherent Point Drift was the one that gave the best results. Also, we compared our method with a simple optical flow tracker and a Kinect based method. From these tests, we concluded that the behavior was comparable, and usually better than a classical optical flow based contour tracker. Respect to the Kinect based method, our results were reasonable and in certain circumstances outperformed those from the OpenNI based method. These are quite good results, specially if we take into account that we are not using a model, and only geometrical information was used.

However, this method is still not good enough for our goal. It depends on static cameras, but we want to track obstacles from images captured by the onboard cameras. Because of that, we started exploring some 3D reconstruction algorithms, founding different approaches. Most of them were based on dense reconstruction, while some others did a simplification of the reconstructed world by assuming certain conditions.

Inside dense reconstruction methods, there are many different algorithms, so choosing one or another is, \emph{a priori}, a difficult task. One of the contributions of this thesis was the development of an automatized framework for the evaluation of dense reconstruction algorithms. This framework allowed testing algorithms from long sequences of images, at different weather and illumination conditions. This solved the problem existing for other previous evaluations in which testing images were taken in laboratories, under controlled conditions; or are based on too short sequences, where ground truth is edited by hand.

We evaluated two different algorithms, \emph{Semi-Global Matching} \citep{Hirschmuller2005} and \ac{ELAS} \citep{Geiger2011}. From the first one, we used two different implementations based on different cost metrics. Moreover, the influence of several filtering strategies was studied. The goal with these evaluations was double: on the one hand, we validate the goodness of our evaluation method, by comparing our results with those obtained with a quite known dataset \citep{geiger2013vision}; on the other, we can conclude which is the best algorithm, the influence of the filters and, finally, which is the best configuration.

In these evaluation tests, we found some interesting results. The use of filtering strategies reduces the number of wrong pixels and enhances the accuracy of the results. We demonstrated that it is possible to do an evaluation on the performance of the methods without the need of a \ac{LIDAR}-based ground truth (which, despite of the great reliability of the statistics obtained with it, is quite expensive in terms of the required equipment and the time needed for post-processing the captured data). The use of a prior on the vehicle movement was successfully exploited to identify a portion of the wrongly reconstructed points, making it suitable for evaluation of big data-sets, thus covering a broad range of environmental conditions. In the other hand, the use of a third camera for evaluation looks feasible, but in practice obtained results were not very discriminative.

We also explored other alternatives different from dense reconstruction. Starting from the works of \cite{benenson2011stixels} and \cite{gunyel2012stixels}, we successfully developed a method for obstacle detection and tracking based on the stixel world described in \cite{badino2009stixel}. With this work, we demonstrated that the use of a two-level tracking outperforms existing stixel based tracking methods. Also, we discovered that the use of the Hellinger distance instead of the \acl{SAD} improved the tracking results, and we saw that the effect of factor $\alpha_{height}$ on tracking results was negligible. Moreover, we showed that if speed is preferred over accuracy, object based tracking is possible, in which objects are obtained through a simple clustering method and then are tracked by using the illumination information between the obstacles.

Going back to the dense reconstruction methods, we also developed a tracking method able to receive a point cloud as input and detect objects and their movement direction and speed, based just on their position in real world coordinates and a particle filter. Although we centered this work on dense stereo reconstruction based point clouds, it is also able to work with point clouds provided by other sensors, like for example \acp{LIDAR}, as we are not using color information. This is done using a modular implementation of the method. The use of a particle filter based approach allows avoiding complex calculations associated to the computation of probabilities, and the use of a voxel grid allows working in three dimensions without increasing the complexity, as well as a more specific knowledge of obstacles, better than other representations of obstacles, like cuboids.

Our method is compared with the method of \cite{danescu2012particle}, concluding that, despite the obtained recall in the detection is almost similar (being slightly better the values obtained by our implementation), the precision obtained with our method outperforms that from \cite{danescu2012particle}. As our implementation is quite modular, we also wanted to know which of the available stereoscopic 3D reconstruction methods is the most suitable to be used as input, concluding that, specially because the required time is smaller, \ac{ELAS} is the best choice. We also did some tests to ensure that the localization method described in \cite{geiger2011stereoscan} is a valid substitute of the localization provided by mechanical odometry, concluding that both of them are equally reliable for our purposes. This localization is used in order to compensate the \emph{Ego-motion} of the vehicle, so we are able to know the absolute movement of the obstacles, and not just their motion relative to the cameras.

In the second part of this thesis, we developed a path planner scheme that allows the vehicle reaching a goal in the map while being able to avoid the obstacles in the neighborhood. We divide this scheme into global and local planner. For the global planner, we developed an innovative strategy for generating trajectories based on \ac{MSVM}, in which each obstacle is a class, and the decision borders are the possible paths. These are joined together through a \acl{NNG} and a \acl{RNG}. At each iteration, the graph is updated with the new obstacles, avoiding the computation of the whole graph again. The advantages of using this method as a base is that we can generate continuous non-linear border lines that allow the creation of smooth, short and safe paths. The use of the \ac{GPU} reduces the required computational time.

This method was compared to other state of the art \ac{SVM} planners, showing that our method outperforms all of them in terms of average distance to obstacles, smoothness and length of the computed paths. It was also compared to other classical methods, like \emph{Voronoi}, obtaining also better results with our approach.

About the local planner, we developed a method that based on the Frenét space, is able to generate smooth paths that allow, at the same time, following the computed trajectory and avoiding obstacles in the way. Generation of tentative paths is simplified as speed is out of the model of tracks generation, so the problem is reduced to the computation of a set of parameters that define a third order polynomial. We also use different lateral offsets with respect to the global plan, so avoidance of obstacles is considered. Then, the use of a cost function allows selecting the best path.

In our tests, we demonstrated that the described method is able to accurately follow a given trajectory. We also saw the effect produced by each cost factor independently, and that their integration conducted to a safe and efficient behavior in the trajectory following procedure.

This planner was integrated with the stixel and the particle filter based methods. As the implemented costmap is reduced to a bidimensional grid in which no temporal information can be included, we were just able to integrate the top-view projection of the detected obstacles.

However, integration of obstacles (taking into account this limitation) was satisfactory, allowing in our simulations to perform a safe navigation between the obstacles existing in both the KITTI \citep{geiger2013vision} and Bahnhoff \citep{ess2009robust} datasets. About using the stixel or the particle filter based approach, it is a decision that must be taken and that depends on the suitability of the environment to the characteristics of each method, as well as on the requirements of each application. Particle filter based method is more generalist, as we do not take special assumptions in this approach; however, if assumptions made for the stixel based approach are fulfilled, this method is much faster, specially if we do not need to perform an accurate tracking (which would allow us to use just the object based tracking method).

\addsec{Future Work}

Despite we have reached the goals that motivated this thesis, there is still much work to do, and many things could be improved. 

\begin{itemize}
 \item One of the main limitations of the image registration based method is the maximal distance and angle between the images. Because of that, we think that using other methods for the matching of features between images is possible. In fact, we have done some tests in which we used the \ac{GPU} for the computation and matching of \ac{SURF} features (\cite{bay2008speeded}), in which times obtained were acceptable for this approach.
 \item We could also implement a shadow detector, in order to reduce the similarity on the illumination requirements.
 \item Some of the techniques used in the image database based method could be also used for other related tasks like the improvement of some of the existing change detection methods for aligned video sequences, as for example those presented in \cite{diego2011video, evangelidis2011slice, evangelidis2011efficient}.
 \item Output obtained for the non rigid contour tracking method described is still not being used at all. We think that this output could be used for many applications, not just related to \ac{ADAS}, but also to motion analysis in videos or \ac{HMI} systems.
 \item We would like to go beyond the use of static bidimensional image sequences, and extend the contour tracking method to be used with 3D information. A way to do that could be the segmentation of a disparity map, in which the contours used would be the borders of the segmented regions. These could be easily transformed to real world coordinates, once the tracking step is finished.
 \item Another way to do that would be through the addition of new dimensions to the points used in the non-rigid point set registration step. Despite the Coherent Point Drift algorithm allows doing that, it would require to optimize the current implementation of this method. This will also allow including color information easily. We started a \ac{CUDA} based implementation of this method, with promising results.
 \item Despite the trilateration based motion detector method used in the results section for the evaluation of the contour tracking approach is reset each frame, we would like to extend it in order to use it for the analysis of the movement of an object. This would require to generate an initial model of the tracked object, but the analysis of its movement could be done through our method.
 \item About the evaluation of the dense reconstruction methods, the use of a third camera for the comparison with a reconstructed virtual image was promising, but results were not as good as expected. In the future, we could use different metrics to measure the similarity between the control camera and virtual images. Also more experiments could be performed, too; including sequences with different weather conditions.
 \item We also want to try new methods for stixel computation. A possibility could be using polar rectification for the combination of tracking and reconstruction in a single process. 
 \item We could use the tracking output as a clue for the clustering process, in which we just consider the stixels for which a correspondence was found.
 \item The particle filter based approach is just using position information for obstacle tracking. We think that results would be improved if we used color information. This would prevent the use of sensors different from stereo cameras, but we could think on an schema in which the information provided by several sensors is combined, being a stereo pair one of them.
 \item We could track the particles along frames, which would improve results and also would increment the knowledge we have about obstacles.
 \item Taking advantage of the big amount of operations that are performed independently for each voxel, we think that a parallel implementation of the method is easy to achieve and will reduce drastically the time required.
 \item Regarding to the path planning methods, there also some work that could be done. For example, new clustering strategies could be applied for the global planner, and the use of \ac{MSVM} could be combined with other classical approaches.
 \item New cost of long-term control strategies could be applied for the generation and selection of the candidate paths in the local planner, as done in \cite{werling2010optimal}.
 \item In the local planner, the final selection of applied steering angle and speed could be improved. Some approaches we have considered are based on the use of a predictive controller.
\end{itemize}

Finally, we would like to improve the costmap computation scheme, so full-3D information (in the form of voxels or other similar approach, for instance) will allow making use of more accurate information about the obstacles. In special, we would like to include temporal information, so we will be able to perform a more intelligent navigation, in which we consider both the present and the future of the environment for a safe and enjoyable trip.